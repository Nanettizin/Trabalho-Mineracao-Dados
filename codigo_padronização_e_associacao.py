# -*- coding: utf-8 -*-
"""Padronização.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13LBSzwCtAreudM6s5IJEAaOFHb56Yf1Y
"""

# Bibliotecas
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from mlxtend.frequent_patterns import apriori, association_rules
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

import warnings

warnings.filterwarnings("ignore", category=DeprecationWarning)

# Célula 1
# Tenta carregar. Se o arquivo usar ';' como separador
df = pd.read_csv('cities_air_quality_water_pollution.18-10-2021.csv')

# Remove espaços vazios antes e depois dos nomes das colunas
df.columns = df.columns.str.strip()
# Remove aspas duplas caso existam nos nomes
df.columns = df.columns.str.replace('"', '')

# Mostra os nomes que o Python encontrou
print("Colunas encontradas:", df.columns.tolist())

# Mostra as 5 primeiras linhaS
df.head()

# Célula 2
# Seleção das features numéricas
features = df[['AirQuality', 'WaterPollution']]

# Padronização (Média 0, Desvio Padrão 1)
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# Criando um DataFrame visual apenas para conferência
pd.DataFrame(features_scaled, columns=['AirQuality', 'WaterPollution']).head()

# Criando um DataFrame temporário com os dados padronizados
df_visualizacao = pd.DataFrame(features_scaled, columns=['AirQuality_Padronizado', 'WaterPollution_Padronizado'])

# Colunas de identificação do DataFrame original
df_visualizacao['City'] = df['City']

# Reorganizando as colunas para o nome ficar na frente
df_visualizacao = df_visualizacao[['City', 'AirQuality_Padronizado', 'WaterPollution_Padronizado']]

# head() com nomes
print(df_visualizacao.head())

# Célula 3
inercias = []
k_range = range(1, 11) # Testando de 1 a 10 grupos

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(features_scaled)
    inercias.append(kmeans.inertia_)

# Plotando o gráfico
plt.figure(figsize=(8, 5))
plt.plot(k_range, inercias, marker='o')
plt.title('Método do Cotovelo (Elbow Method)')
plt.xlabel('Número de Clusters (k)')
plt.ylabel('Inércia')
plt.grid(True)
plt.show()

# Célula 4
k_escolhido = 3  # 3 se parece um bom número

# Rodando o modelo final
kmeans_final = KMeans(n_clusters=k_escolhido, random_state=42, n_init=10)
clusters = kmeans_final.fit_predict(features_scaled)

# Salvando o resultado na tabela original
df['Cluster'] = clusters
print("Agrupamento concluído!")

# Célula 5
# Visualização Gráfica
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='AirQuality', y='WaterPollution', hue='Cluster', palette='viridis', s=50)
plt.title(f'Segmentação de Cidades (k={k_escolhido})')
plt.xlabel('Qualidade do Ar (0-100)')
plt.ylabel('Poluição da Água (0-100)')
plt.legend(title='Cluster')
plt.show()

# Análise dos Centróides (Médias reais)
perfil = df.groupby('Cluster')[['AirQuality', 'WaterPollution']].mean().sort_values('AirQuality')
print("\n--- Perfis Ambientais Identificados (Médias) ---")
print(perfil)

# Célula 6 - Análise Focada no Brasil com Estilização Visual

# 1. Definindo os nomes dos perfis
nomes_clusters = {
    0: "Sustentabilidade (Ar Bom / Água Boa)",
    1: "Crise Dupla (Ar Ruim / Água Ruim)",
    2: "Desafio Hídrico (Ar Bom / Água Poluída)"
}

# 2. Filtrando apenas o Brasil
brasil_df = df[df['Country'].str.contains('Brazil', case=False, na=False)].copy()
brasil_df['Perfil'] = brasil_df['Cluster'].map(nomes_clusters)

# 3. Selecionando as Cidades-Chave
cidades_alvo = ['Manaus', 'Sao Luis', 'Salvador', 'Porto Alegre', 'Sao Paulo', 'Rio De Janeiro', 'Curitiba', 'Brasilia']

# Criamos dois grupos: As cidades do estudo de caso e o resto
destaque_df = brasil_df[brasil_df['City'].isin(cidades_alvo)].sort_values('Cluster')
resto_df = brasil_df[~brasil_df['City'].isin(cidades_alvo)].head(5)

# Juntamos tudo para exibir
apresentacao_brasil = pd.concat([destaque_df, resto_df])

# 4. Exibindo a Tabela Bonita
display(apresentacao_brasil[['City', 'Perfil', 'AirQuality', 'WaterPollution']]
        .style
        .format({'AirQuality': '{:.1f}', 'WaterPollution': '{:.1f}'})
        .hide()
)

# 5. Estatística Rápida do Brasil
print("\n--- RESUMO DO CENÁRIO BRASILEIRO ---")
contagem_br = brasil_df['Perfil'].value_counts()
print(contagem_br)

# Contagem absoluta
contagem = df['Cluster'].value_counts().sort_index()

# Contagem percentual
porcentagem = df['Cluster'].value_counts(normalize=True).sort_index() * 100

# Exibindo os nomes
nomes_clusters = {
    0: "Sustentabilidade",
    1: "Crise Dupla",
    2: "Desafio Hídrico"
}

print("--- QUANTIDADE DE CIDADES POR PERFIL ---")
for i in range(3):
    nome = nomes_clusters.get(i)
    qtd = contagem[i]
    perc = porcentagem[i]
    print(f"Cluster {i} ({nome}): {qtd} cidades ({perc:.1f}%)")

# Célula 7 - Visualização Avançada (Dashboard)
import matplotlib.pyplot as plt
import seaborn as sns

# Mapeamento dos nomes (Garanta que os IDs 0, 1, 2 batem com sua análise da Célula 5)
mapa_nomes = {
    0: "Sustentabilidade",   # Ar Bom / Água Boa
    1: "Crise Dupla",        # Ar Ruim / Água Ruim
    2: "Desafio Hídrico"     # Ar Bom / Água Ruim
}

# Criando coluna temporária para legendas
df['Nome_Cluster'] = df['Cluster'].map(mapa_nomes)

# Configurando estilo
sns.set_style("whitegrid")

# GRÁFICO 1: Scatter Plot
plt.figure(figsize=(10, 7))
sns.scatterplot(
    data=df,
    x='AirQuality',
    y='WaterPollution',
    hue='Nome_Cluster',
    palette='viridis',
    s=60,
    alpha=0.8
)
plt.title('Distribuição dos Perfis Ambientais Globais', fontsize=14, fontweight='bold')
plt.xlabel('Qualidade do Ar (Maior = Mais Limpo)', fontsize=11)
plt.ylabel('Poluição da Água (Maior = Mais Sujo)', fontsize=11)
plt.legend(title='Perfil Ambiental', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# GRÁFICO 2: Boxplots (Comparação Estatística)
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Ar
sns.boxplot(data=df, x='Nome_Cluster', y='AirQuality', palette='viridis', ax=axes[0])
axes[0].set_title('Comparação: Qualidade do Ar', fontweight='bold')
axes[0].set_ylabel('Índice de Qualidade')
axes[0].set_xlabel('')

# Água
sns.boxplot(data=df, x='Nome_Cluster', y='WaterPollution', palette='viridis', ax=axes[1])
axes[1].set_title('Comparação: Poluição da Água', fontweight='bold')
axes[1].set_ylabel('Índice de Poluição')
axes[1].set_xlabel('')

plt.tight_layout()
plt.show()

# Célula 8 - Preparação das Categorias
from mlxtend.frequent_patterns import apriori, association_rules

# Definindo 5 faixas (Bins) de 20 em 20
# 0-20: Muito Baixo | 20-40: Baixo | 40-60: Médio | 60-80: Alto | 80-100: Muito Alto
bins = [0, 20, 40, 60, 80, 100]
labels = ['Muito Baixo', 'Baixo', 'Médio', 'Alto', 'Muito Alto']

# Criando um DataFrame novo só para isso
df_assoc = pd.DataFrame()

# Transformando os números em texto (Categorias)
df_assoc['Ar_Cat'] = pd.cut(df['AirQuality'], bins=bins, labels=labels)
df_assoc['Agua_Cat'] = pd.cut(df['WaterPollution'], bins=bins, labels=labels)

# Visualizando como ficou a classificação
print("--- Exemplo da Categorização com 5 Níveis ---")
print(df_assoc.head())

# Célula 9 - Transformação One-Hot Encoding
# O Apriori não lê texto, ele precisa de colunas binárias (True/False)
basket = pd.get_dummies(df_assoc)

# Mostra como a tabela ficou "larga" agora
print("--- Tabela Binária para o Algoritmo ---")
print(basket.head())

# Célula 10 - Rodando o Algoritmo Apriori
# min_support=0.03: Combinações que apareçam em pelo menos 3% das cidades
# Se não aparecer nada, diminua para 0.01
frequent_itemsets = apriori(basket, min_support=0.03, use_colnames=True)

print(f"Foram encontrados {len(frequent_itemsets)} conjuntos frequentes de itens.")

# Célula 11 - Gerando as Regras de Associação
# min_threshold=0.2: Mínimo 20% de confiança
regras = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.2)

# Filtrando e Ordenando
cols_uteis = ['antecedents', 'consequents', 'support', 'confidence']
regras_ordenadas = regras[cols_uteis].sort_values(by='confidence', ascending=False)

print("--- TOP 10 REGRAS DE ASSOCIAÇÃO (5 CATEGORIAS) ---")
print(regras_ordenadas.head(10))

# Célula 12 - Limpeza e Formatação Visual

# 1. Função para limpar o texto
def limpar_texto(itemset):
    # O Apriori devolve um conjunto congelado, pegamos o primeiro item
    texto = list(itemset)[0]

    # Substituições para deixar bonito
    texto = texto.replace("Ar_Cat_", "Ar: ")
    texto = texto.replace("Agua_Cat_", "Água: ")
    texto = texto.replace("_", " ") # Tira qualquer underline extra
    return texto

# 2. Criando colunas novas com os nomes limpos
regras['SE (Causa)'] = regras['antecedents'].apply(limpar_texto)
regras['ENTAO (Efeito)'] = regras['consequents'].apply(limpar_texto)

# 3. Exibindo a tabela formatada
colunas_bonitas = ['SE (Causa)', 'ENTAO (Efeito)', 'confidence', 'lift']

print("--- REGRAS DE ASSOCIAÇÃO (FORMATO FINAL) ---")
# Mostrando as top 10 com formatação de porcentagem
display(regras[colunas_bonitas].sort_values(by='confidence', ascending=False).head(10).style.format({
    'confidence': '{:.1%}',  # Ex: 60.8%
    'lift': '{:.2f}'         # Ex: 1.50
}))

# Célula 12 - Transformando Regras em Gráficos

# 1. Preparando os dados para plotagem
# O algoritmo devolve os nomes como conjuntos congelados (frozenset).
# Precisamos transformar em texto simples para colocar no gráfico.
regras['ant_nome'] = regras['antecedents'].apply(lambda x: ', '.join(list(x)))
regras['con_nome'] = regras['consequents'].apply(lambda x: ', '.join(list(x)))

# Configuração de Estilo
sns.set_style("whitegrid")

# GRÁFICO A: Scatter Plot (Visão Geral da Estatística)
plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=regras,
    x="support",
    y="confidence",
    size="lift",
    hue="lift",
    palette="viridis",
    sizes=(50, 300),
    alpha=0.7
)
plt.title('Distribuição das Regras: Confiança vs. Suporte', fontsize=14, fontweight='bold')
plt.xlabel('Suporte (Frequência da regra)', fontsize=11)
plt.ylabel('Confiança (Certeza da regra)', fontsize=11)
plt.legend(title='Lift (Força)', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# GRÁFICO B: Heatmap (A Matriz da Verdade)
# Vamos pivotar os dados para criar uma matriz Antecedente x Consequente
matriz_regras = regras.pivot(index='ant_nome', columns='con_nome', values='confidence')

plt.figure(figsize=(12, 8))
sns.heatmap(
    matriz_regras,
    annot=True,      # Escreve o número da confiança dentro do quadrado
    fmt=".2f",       # Formatação com 2 casas decimais
    cmap="YlGnBu",   # Cor: Amarelo para Verde/Azul (Cores frias são ótimas para água/ar)
    cbar_kws={'label': 'Confiança (Probabilidade)'}
)
plt.title('Mapa de Calor das Associações (Causa -> Efeito)', fontsize=14, fontweight='bold')
plt.xlabel('Consequência (ENTÃO...)', fontsize=12)
plt.ylabel('Antecedente (SE...)', fontsize=12)
plt.yticks(rotation=0)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Célula 13 - Visualização Gráfica com Nomes Limpos
import seaborn as sns
import matplotlib.pyplot as plt

# Configuração de Estilo
sns.set_style("whitegrid")

# GRÁFICO 1: Scatter Plot (Visão Geral)
plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=regras,
    x="support",
    y="confidence",
    size="lift",
    hue="lift",
    palette="viridis",
    sizes=(50, 300),
    alpha=0.7
)
plt.title('Distribuição das Regras: Confiança vs. Suporte', fontsize=14, fontweight='bold')
plt.xlabel('Suporte (Frequência)', fontsize=11)
plt.ylabel('Confiança (Certeza)', fontsize=11)
plt.legend(title='Lift (Força)', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# GRÁFICO 2: Heatmap (Mapa de Calor)
# Usando as colunas novas 'SE (Causa)' e 'ENTAO (Efeito)'
matriz_regras = regras.pivot(index='SE (Causa)', columns='ENTAO (Efeito)', values='confidence')

plt.figure(figsize=(12, 8))
sns.heatmap(
    matriz_regras,
    annot=True,
    fmt=".0%",       # Mostra em porcentagem (ex: 60%)
    cmap="YlGnBu",   # Cores: Amarelo para Verde/Azul
    cbar_kws={'label': 'Confiança (Probabilidade)'}
)
plt.title('Mapa de Calor: Relações entre Ar e Água', fontsize=14, fontweight='bold')
plt.xlabel('Consequência (Efeito)', fontsize=12)
plt.ylabel('Antecedente (Causa)', fontsize=12)
plt.yticks(rotation=0)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()